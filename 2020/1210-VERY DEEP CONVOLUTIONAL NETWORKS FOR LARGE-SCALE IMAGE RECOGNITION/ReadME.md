VGG：Visual Geometry Group 以实验室命名

### 摘要：
主要贡献是使用非常小的（3×3）卷积滤波器架构对网络深度进行增加；
### ConvNet配置：
#### 结构：
输入是224\*224的图像，预处理是每个像素减去整个训练集上计算的RGB均值（就是所有像素的rgb均值）；

一堆卷积层，每层是3\*3，池化用的最大池化，接在部分的卷积层后面，池化为2\*2，步长为2；

卷积层后面是三个FC，最后接softmax接输出。使用ReLU作为激活函数，cut掉了alexnet的LRN模块。

具体的结构：VGG-16/19比较常用作backbone；

#### 讨论：
和之前网络的改进情况；

两个3×3卷积层堆叠（没有空间池化）有5×5的有效感受野；

但是参数由25降到了18；

可以减小参数的同时不丧失感受野；就是说这样搞网络效果比较好。

#### 介绍训练和评估的细节：
采用批量的梯度下降；动量参数是0.9，训练过程用了权重衰减的正则化技巧，L2范数；学习率设置为0.01，然后当验证集的准确率停止改善时，减小10倍，学习率总共降低3次；总共37万次迭代，一共74个epochs；

初始化：先用随机初始化训练VGG-A，因为A网络比较浅，其他网络就用这个网络的训练结果作为初始化（前四个卷积层和后面的三个全连接层）；对于预训练层不减小学习率，其他层权重初始化是用的0均值，0.01为标准差的高斯分布，bias初始化为0；

224\*224的输入是从训练图像resize之后随即裁剪得到的（每个图像在每次SGD过程只裁剪一次），然后再进行随机水平翻转和随机RGB颜色偏移；

#### 训练图像大小：
就是先把训练图片等比缩放，然后在缩放后的图片上随机裁剪。缩放后的短边记为S，S只要大于224就行；两种设置S的方式：一是固定S，进行单尺度的训练，论文设置了S为256和384，先用256进行裁剪训练，然后用384训练，384的参数用256的进行初始化；

二是S设置多尺度训练：每个训练图像resize成随机的S，S范围是[256，512]，实现多尺度。训练的参数采用固定S的384训练的结果；

multi-crop 多尺度数据：即对图像进行多样本的随机裁剪

#### 预测：
先把测试图片等比缩放到Q，Q不一定等于S，对于一个S，使用多个Q进行测试，然后去平均；

#### 优点总结：
采用更小的卷积核，参数减小；去掉了LRN模块；采用了1\*1的卷积核（mobile net用来扩维，resnet用来缩小维度）；多尺度进行训练；
