https://blog.csdn.net/qq_32768091/article/details/80778815 
摘要：
我们发明了一类有效的为了可移动的设备和嵌入式视觉的应用的模型叫做MobileNets. MobileNets是基于一种使用深度可分割卷积depthwise separable convolutions去建立轻量型网络结构的流线型结构。我们引进了两个简单的超参数，这两个超参数在延迟和准确率方面达到了平衡。这些超参数允许模型建立者对于他们的模型去选择正确大小的模型建立在这个问题的限制上，我们进行了昂贵的实验在资源和准确率平衡方面，同时在Imagenet 分类方面对比其它受欢迎的模型表现的不错。 然后进行了广泛的运用Mobilenet去阐述它的有效性，包括目标检测，细粒度分类，面部识别和大规模geo定位
简介：
small, low latency 用两个超参数可以构建简单并且低资源消耗的网络，可以很容易的满足移动设备和嵌入式视觉应用的需求。
之前的工作：
目前搭建小并且有效的网络方式：许多不同的方法可以被一般的归类为压缩提前训好的网络或者直接训练小型网络。MobileNets既考虑了大小又考虑了速度。
网络结构：
在这部分我们首先描述了MobilneNet模型的核心层是建立在深度可分割过滤器上。然后描述了MobileNet 网络结构，包括对两个模型收缩参数的描述（宽度乘数和分辨率乘数）
1 深度可分割卷积：
这个MobileNet 模型是建立在深度可分割卷积上，深度可分割卷积是一种因式分解卷积，它把标准的卷积分解成一个深度卷积和一个1*1的点卷积。对于MobileNet这个深度卷积把单一过滤应用在每个输入通道上。然后点卷积运用1*1大小的卷积是结合深度卷积的输出。一种标准的卷积既能过滤输入，又能在一步中将输入组合成一组新的输出（标准的卷积是一步完成的）。深度可分割卷积把这个分成两步，一个分割层为了过滤，另一个分割层为了结合。这个因式分解彻底的减少了计算量和模型大小。图2显示了一个标准的卷积被分解为一个深度卷积和一个181的点卷积。
一个标准的卷积层接受输入列如DFDFXDFDFXM特征图F并产生DFDFXDFDFXM特征图G,DFDF是空间宽度和高度对于一个输入的正方形特征图，M是输入通道大小，D−GD−G是输出的正方形特征图的空间宽度和高度，N是输出通道大小。
标准卷积层由卷积核K参数化的计算为DKDKXDKDKXMXN,DKDK是卷积核的空间温度，M是输入通道大小，N是输出通道大小，和之前定义的一样。
标准卷积的特征图输出计算是（假设strides是1padding也是1）：

标准卷积运算量计算为：
DKDKDKDK*M*NDFDF*DFDF
运算量依赖于输入通道M,输出通道N和卷积核大小DKDK以及特征图大小DFDF. MobileNet解决了这种关系和他们的交互。首先使用利用深度可分割网络去打破输出通道和卷积核大小的交互。
标准的卷积操作对过滤特征有影响建立在卷积核和解和特征目的是阐述新的表达，过滤和结合步骤可以被分成两部分通过使用因式分解卷积叫做深度可分割卷积未来充分减少运算量。
深度可分割网络是由两层组成的：深度卷积和点卷积，我们使用深度卷积把单个卷积核运用在每个输入通道上，然后用1*1点卷积去结合深度卷积层的输出。MobileNet在每一层后使用batchnorm和Relu
深度卷积对每个输入通道的单个卷积可以被写作：
MobileNet使用3×3深度可分割卷积它的计算量比标准卷积少8到9倍但在精度上只有很小的降低在第四节。空间维度的额外分解，如in[16, 31]并没有节省太多额外的计算量因为很少的计算被花费在深度卷积中（就是说作者认为没有必要再进行对depthwise的分解了）。

核心就是将标准的卷积分成了depthwise卷积和pointwise卷积，前者用来filter，后者用来combine，这样能将标准卷积的连乘计算量大大降低。
2 网络结构和训练
MobileNet结构是构建在深度可分离的卷积上的，但第一层除外，它是全卷积。通过如此简单的术语定义网络，我们能够轻松地探索网络拓扑以找到良好的网络。表1定义了MobileNet架构。除了最后的完全连接层为了将输出量送入SoftMax层进行分类没有使用非线性，其余都层均使用了批量归一化和Relu非线性。图3将标准卷积，批量归一化和Relu非线性与具有深度卷积、1 × 1 1×11×1逐点卷积以及每个卷积层之后的批量归一化和Relu非线性的分解层进行对比。下采样在深度卷积和第一层中用跨步卷积处理（就是说通过stride设置为2进行下采样）。最终平均池化会在完全连接的层之前将空间分辨率降低到1。将纵深卷积和逐点卷积计算为单独的层，MobileNet有28层。

仅仅用少量的Mult-Adds来定义网络是不够的。同样重要的是要确保这些操作可以有效地实现其功能。例如，非结构化的稀疏矩阵操作通常不会比密集矩阵操作快，直到达到非常高的稀疏程度。我们的模型结构将几乎所有的计算放在密集的1×1卷积中。这可以通过高度优化的通用矩阵乘法(GEMM)函数来实现。卷积通常由GEMM实现，但需要在内存中调用im2col进行初始重新排序，以便将其映射到GEMM。例如，这种方法被用于流行的Coffe框架[15]。1×1卷积不需要在内存中重新排序，可以直接使用GEMM实现，GEMM是最优化的数值线性代数算法之一。MobileNet在1 × 1 1×11×1卷积中花费了95%的计算时间，也有75%的参数，如表2所示。几乎所有的附加参数都在完全连接层中。
MobileNet模型在TensorFlow[1]中使用RMSprop[33]进行训练，具有类似于InceptionV3[31]的异步梯度下降。然而，与训练大模型相反，我们使用较少的正则化和数据增强技术，因为小模型的过拟合问题较少。此外，我们发现在深度滤波器上放置非常少的或没有权重衰减(L2正则化)是很重要的，因为它们的参数太少了。对于下一节中的ImageNet基准测试，所有模型都使用相同的训练参数进行训练，而不考虑模型的大小（就是说因为模型参数较少，所以不需要担心过拟合）。
3 宽度乘数 更薄的模型 压缩通道数
就是定义了一个宽度因子，宽度乘数α 的作用是使每一层的网络均匀变薄。对于给定的层和宽度乘子α ，输入信道数M 变为α M ，输出信道数N 变为α N 。这样网络进一步变小，通过这个因子可以在网络大小和精度之间找到一个权衡。
4 分辨率乘数 减少表示 压缩输入图像的尺寸
就是定义了一个分辨率因子，减小输入图片的分辨率，
模型结构图：
 
https://blog.csdn.net/lihuanyu520/article/details/104731974
mobilenet就是用深度可分离卷积替代传统的卷积，来降低计算量和参数量，但是效果却没有降低太多，适合在移动端或者其他小型的终端上使用。
那缺点是什么呢？一个是精度会下降大约1%，另一个是训练速度有可能会慢一点。现在（2019年）V3 已经推出来了，可以优先选用 V3。
深度可分离的卷积操作：当kernel的size是3时，深度可分离卷积比传统卷积少8到9倍的计算量。这种深度可分离卷积虽然很好的减少计算量，但同时也会损失一定的准确率。从下图可以看到，使用传统卷积的准确率比深度可分离卷积的准确率高约1%，但计算量却增大了9倍。
 
v1中使用了RELU6作为激活函数，这个激活函数在float16/int8的嵌入式设备中效果很好，能较好地保持网络的鲁棒性。
http://www.atyun.com/39076.html
